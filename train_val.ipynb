{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfb16deb",
   "metadata": {},
   "source": [
    "# InSAR denoiser training, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c15fbdcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import torch\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import math\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import random\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7f1291",
   "metadata": {},
   "source": [
    "## Dataset construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e251d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths\n",
    "main_dir = '/home/jovyan/InSAR_denoising_CNN'\n",
    "train_signal_dir = f'{main_dir}/train_subsets_v3/veloc/'\n",
    "train_noise_dir = f'{main_dir}/train_subsets_v3/int/'\n",
    "train_dem_dir = f'{main_dir}/train_subsets_v3/dem/'\n",
    "train_era5_dir = f'{main_dir}/train_subsets_v3/era5/'\n",
    "\n",
    "val_signal_dir = f'{main_dir}/val_subsets_v3/veloc/'\n",
    "val_noise_dir = f'{main_dir}/val_subsets_v3/int/'\n",
    "val_dem_dir = f'{main_dir}/val_subsets_v3/dem/'\n",
    "val_era5_dir = f'{main_dir}/val_subsets_v3/era5/'\n",
    "\n",
    "# list files\n",
    "train_signal_fns = os.listdir(train_signal_dir)\n",
    "train_noise_fns = os.listdir(train_noise_dir)\n",
    "train_dem_fns = os.listdir(train_dem_dir)\n",
    "train_era5_fns = os.listdir(train_era5_dir)\n",
    "\n",
    "val_signal_fns = os.listdir(val_signal_dir)\n",
    "val_noise_fns = os.listdir(val_noise_dir)\n",
    "val_dem_fns = os.listdir(val_dem_dir)\n",
    "val_era5_fns = os.listdir(val_era5_dir)\n",
    "\n",
    "# exclude non tif files, e.g. metadata\n",
    "def list_tifs(my_fns):\n",
    "    my_list = []\n",
    "    for i in my_fns:\n",
    "        if i[-4:] == '.tif':\n",
    "            my_list.append(i)\n",
    "    return my_list\n",
    "\n",
    "train_signal_list = list_tifs(train_signal_fns)\n",
    "train_noise_list = list_tifs(train_noise_fns)\n",
    "train_dem_list = list_tifs(train_dem_fns)\n",
    "train_era5_list = list_tifs(train_era5_fns)\n",
    "\n",
    "val_signal_list = list_tifs(val_signal_fns)\n",
    "val_noise_list = list_tifs(val_noise_fns)\n",
    "val_dem_list = list_tifs(val_dem_fns)\n",
    "val_era5_list = list_tifs(val_era5_fns)\n",
    "\n",
    "# create training list of only scenes shared in all necessary dirs\n",
    "train_list = []\n",
    "for fn in train_signal_list:\n",
    "    if fn in train_noise_list and fn in train_dem_list and fn in train_era5_list:\n",
    "        train_list.append(fn)\n",
    "        \n",
    "val_list = []\n",
    "for fn in val_signal_list:\n",
    "    if fn in val_noise_list and fn in val_dem_list and fn in val_era5_list:\n",
    "        val_list.append(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e37d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training and validation data \n",
    "#train_list, val_list = train_test_split(train_list, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47c55005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transforms\n",
    "my_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomVerticalFlip(0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d2db807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset \n",
    "class dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_list, signal_dir, noise_dir, dem_dir, era5_dir, transform=None, \n",
    "                 norm=True, center=True, blurnoise=False):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.signal_dir = signal_dir\n",
    "        self.noise_dir = noise_dir\n",
    "        self.dem_dir = dem_dir\n",
    "        self.era5_dir = era5_dir\n",
    "        self.norm = norm\n",
    "        self.center = center\n",
    "        self.blurnoise = blurnoise\n",
    "        \n",
    "    #dataset length\n",
    "    def __len__(self):\n",
    "        self.filelength = len(self.file_list)\n",
    "        return self.filelength\n",
    "    \n",
    "    #load images\n",
    "    def __getitem__(self,idx):\n",
    "        signal_path = self.signal_dir+self.file_list[idx]\n",
    "        noise_path = self.noise_dir+self.file_list[idx]\n",
    "        dem_path = self.dem_dir+self.file_list[idx]\n",
    "        era5_path = self.era5_dir+self.file_list[idx]\n",
    "        \n",
    "        signal = self.transform(Image.open(signal_path))\n",
    "        noise = self.transform(Image.open(noise_path))\n",
    "        dem = self.transform(Image.open(dem_path))\n",
    "        era5 = self.transform(Image.open(era5_path))\n",
    "        \n",
    "        # Generate era5 noise estimates\n",
    "        era5 = era5*(0.05546576/12.5663706) # convert phase to displacement\n",
    "        era5 = (noise-(era5*-1)) \n",
    "        \n",
    "        # Blur noise\n",
    "        if self.blurnoise == True: # blur noise to mitigate noise from non atmospheric sources\n",
    "            gblur = transforms.GaussianBlur(kernel_size=(7, 7), sigma=5)\n",
    "            noise = gblur(noise)\n",
    "        \n",
    "        # Generate scaled training images\n",
    "        scalar = np.round(np.random.lognormal(0.05, 1.), 3)\n",
    "        signal = signal*scalar\n",
    "        train = noise+signal\n",
    "        \n",
    "        # Set era reference point\n",
    "        ref_index = signal.abs().argmin().item() # location of lowest signal in velocity map\n",
    "        corr_diff = (train.flatten()[ref_index] - era5.flatten()[ref_index]).item()\n",
    "        era5 = era5+corr_diff \n",
    "        \n",
    "        # correct train\n",
    "        era5_corr = train-era5 #produce era5 corrected train image\n",
    "        \n",
    "        # correct hp\n",
    "        hp_filter = transforms.GaussianBlur(kernel_size=(25, 25), sigma=3)\n",
    "        train_filtered = hp_filter(train)\n",
    "        hp_corr = train - train_filtered\n",
    "        \n",
    "        # normalization between -1 and 1 as in Zhao et al. https://doi.org/10.1016/j.isprsjprs.2021.08.009\n",
    "        if self.norm == True:\n",
    "            if train.min() < signal.min():\n",
    "                norm_min = train.min()\n",
    "            else:\n",
    "                norm_min = signal.min()\n",
    "                \n",
    "            if train.max() > signal.max():\n",
    "                norm_max = train.max()\n",
    "            else:\n",
    "                norm_max = signal.max()\n",
    "            \n",
    "            signal = 2*(((signal-norm_min)/(norm_max-norm_min)))-1\n",
    "            noise  = 2*(((noise-(noise.min()))/(noise.max()-(noise.min()))))-1\n",
    "            dem = 2*(((dem-dem.min())/(dem.max()-dem.min())))-1\n",
    "            train = 2*(((train-norm_min)/(norm_max-norm_min)))-1\n",
    "            era5 = 2*(((era5-era5.min())/(era5.max()-era5.min())))-1\n",
    "            era5_corr = 2*(((era5_corr-norm_min)/(norm_max-norm_min)))-1\n",
    "            hp_corr = 2*(((hp_corr-norm_min)/(norm_max-norm_min)))-1\n",
    "        \n",
    "        if self.center == True: # center target images on 0 \n",
    "            center_median = signal.median()\n",
    "            train = train-center_median\n",
    "            signal = signal-center_median\n",
    "            era5_corr = era5_corr-center_median\n",
    "            hp_corr = hp_corr-center_median\n",
    "         \n",
    "        \n",
    "        return train, signal, noise, era5, dem, era5_corr, hp_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05c60ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "train_data = dataset(train_list, train_signal_dir, train_noise_dir, train_dem_dir, train_era5_dir, transform=my_transforms, blurnoise=True)\n",
    "val_data = dataset(val_list, val_signal_dir, val_noise_dir, val_dem_dir, val_era5_dir, transform=my_transforms, blurnoise=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size=16, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset = val_data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd171acc",
   "metadata": {},
   "source": [
    "## Examine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5109f2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 5\n",
    "\n",
    "for i, (sample, signal_target, noise_target, era5_noise, dem, era5_corr, hp_corr) in enumerate(val_loader):\n",
    "    if i < num_images:\n",
    "            f, ax = plt.subplots(1, 5, figsize=(20,7))\n",
    "            ax[0].imshow(sample.squeeze(), cmap='RdBu', vmin=-2, vmax=2) \n",
    "            ax[0].set_title('training')\n",
    "            ax[1].imshow(signal_target.squeeze(), cmap='RdBu', vmin=-2, vmax=2)\n",
    "            ax[1].set_title('target signal')\n",
    "            ax[2].imshow((sample.squeeze()-signal_target.squeeze()), cmap='RdBu', vmin=-2, vmax=2)\n",
    "            ax[2].set_title('target noise')\n",
    "            ax[3].imshow(era5_noise.squeeze(), cmap='RdBu', vmin=-2, vmax=2)\n",
    "            ax[3].set_title('ERA5 noise')\n",
    "            ax[4].imshow(dem.squeeze(), cmap='gray', vmin=-2, vmax=2)\n",
    "            ax[4].set_title('DEM')\n",
    "            f.tight_layout()\n",
    "            \n",
    "            f, ax = plt.subplots(1, 5, figsize=(15,3))\n",
    "            ax[0].hist(sum(sum(sum(sample.tolist(), []), []), []), bins=40)\n",
    "            ax[1].hist(sum(sum(sum(signal_target.tolist(), []), []), []), bins=40)\n",
    "            ax[2].hist(sum(sum(sum((sample-signal_target).tolist(), []), []), []), bins=40)\n",
    "            ax[3].hist(sum(sum(sum(era5_noise.tolist(), []), []), []), bins=40)\n",
    "            ax[4].hist(sum(sum(sum(dem.tolist(), []), []), []), bins=40)\n",
    "            f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3c0951",
   "metadata": {},
   "source": [
    "## Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b93c0a62-ec46-4f9e-b680-6105ca70ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_channels, out_channels, stride=1, padding=1, bias=True):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=padding, bias=bias)\n",
    "\n",
    "\n",
    "def conv1x1(in_channels, out_channels):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "\n",
    "\n",
    "def check_valid_activation(choice):\n",
    "    if choice not in ['relu', 'lrelu', 'prelu']:\n",
    "        raise ValueError(f\"'{choice}' is not a valid activation function. Choose among ['relu', 'lrelu', 'prelu'].\\n\")\n",
    "\n",
    "\n",
    "def upconv(in_channels, out_channels, mode='transpose'):\n",
    "    # stride=2 implies upsampling by a factor of 2\n",
    "    get_up_mode = nn.ModuleDict([\n",
    "        ['bilinear', nn.Sequential(nn.Upsample(mode='bilinear', scale_factor=2), conv1x1(in_channels, out_channels))],\n",
    "        ['transpose', nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)]\n",
    "    ])\n",
    "\n",
    "    return get_up_mode[mode]\n",
    "\n",
    "\n",
    "def get_activation(choice):\n",
    "    activation_functions = nn.ModuleDict([\n",
    "        ['relu', nn.ReLU(inplace=True)],\n",
    "        ['lrelu', nn.LeakyReLU(inplace=True)],\n",
    "        ['prelu', nn.PReLU()]\n",
    "        ])\n",
    "    return activation_functions[choice]\n",
    "\n",
    "\n",
    "def conv_block(in_channels, out_channels, activation='relu', do_BN=True, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Partial encoder block consisting of a 3×3 convolutional layer with stride 1, followed by batch normalization\n",
    "    (optional) and a non-linear activation function.\n",
    "    \"\"\"\n",
    "\n",
    "    if do_BN:\n",
    "        return nn.Sequential(\n",
    "            conv3x3(in_channels, out_channels, bias=False, *args, **kwargs),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            get_activation(activation)\n",
    "        )\n",
    "    else:\n",
    "        return nn.Sequential(\n",
    "            conv3x3(in_channels, out_channels, bias=True, *args, **kwargs),\n",
    "            get_activation(activation)\n",
    "        )\n",
    "\n",
    "\n",
    "def conv_up_block(in_channels, out_channels, activation='relu', do_BN=True, up_mode='transpose', *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Decoder block consisting of an up-convolutional layer, followed by a 3×3 convolutional layer with stride 1,\n",
    "    batch normalization (optional), and a non-linear activation function.\n",
    "    \"\"\"\n",
    "\n",
    "    if do_BN:\n",
    "        return nn.Sequential(\n",
    "            upconv(in_channels, in_channels, up_mode),\n",
    "            nn.Sequential(\n",
    "                conv3x3(in_channels, out_channels, bias=False, *args, **kwargs),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                get_activation(activation))\n",
    "            )\n",
    "    else:\n",
    "        return nn.Sequential(\n",
    "            upconv(in_channels, in_channels, up_mode),\n",
    "            nn.Sequential(\n",
    "                conv3x3(in_channels, out_channels, bias=True, *args, **kwargs),\n",
    "                get_activation(activation))\n",
    "            )\n",
    "\n",
    "\n",
    "def bottleneck(in_channels, out_channels, activation='relu', do_BN=True, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Bottleneck block.\n",
    "    \"\"\"\n",
    "\n",
    "    if do_BN:\n",
    "        return nn.Sequential(\n",
    "            conv3x3(in_channels, out_channels, bias=False, *args, **kwargs),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            get_activation(activation)\n",
    "        )\n",
    "    else:\n",
    "        return nn.Sequential(\n",
    "            conv3x3(in_channels, out_channels, bias=True, *args, **kwargs),\n",
    "            get_activation(activation)\n",
    "        )\n",
    "\n",
    "\n",
    "class SkipConnection(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SkipConnection, self).__init__()\n",
    "\n",
    "    def forward(self, x_skip, x_up):\n",
    "        return x_skip + x_up\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_input_channels=2, start_kernel=64, max_filter_depth=512, depth=7,\n",
    "                 act_fn_encoder='relu', act_fn_decoder='relu', act_fn_bottleneck='relu', up_mode='transpose',\n",
    "                 do_BN=True, bias_conv_layer=False, outer_skip=True, outer_skip_BN=False):\n",
    "        \"\"\"\n",
    "        UNet network architecture.\n",
    "        :param n_input_channels:    int, number of input channels\n",
    "        :param start_kernel:        int, number of filters of the first convolutional layer in the encoder\n",
    "        :param max_filter_depth:    int, maximum filter depth\n",
    "        :param depth:               int, number of downsampling and upsampling layers (i.e., number of blocks in the\n",
    "                                    encoder and decoder)\n",
    "        :param act_fn_encoder:      str, activation function used in the encoder\n",
    "        :param act_fn_decoder:      str, activation function used in the decoder\n",
    "        :param act_fn_bottleneck:   str, activation function used in the bottleneck\n",
    "        :param up_mode:             str, upsampling mode\n",
    "        :param do_BN:               boolean, True to perform batch normalization after every convolutional layer,\n",
    "                                    False otherwise\n",
    "        :param bias_conv_layer:     boolean, True to activate the learnable bias of the convolutional layers,\n",
    "                                    False otherwise\n",
    "        :param outer_skip:          boolean, True to activate the long residual skip connection that adds the\n",
    "                                    initial DSM to the output of the last decoder layer, False otherwise\n",
    "        :param outer_skip_BN:       boolean, True to add batch normalization to the long residual skip connection,\n",
    "                                    False otherwise\n",
    "        \"\"\"\n",
    "\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        check_valid_activation(act_fn_encoder)\n",
    "        check_valid_activation(act_fn_decoder)\n",
    "        check_valid_activation(act_fn_bottleneck)\n",
    "\n",
    "        if up_mode not in ['transpose', 'bilinear']:\n",
    "            raise ValueError(f\"'{up_mode}' is not a valid mode for upsampling. Choose among ['transpose', 'bilinear'] \"\n",
    "                             \"to specify 'up_mode'.\\n\")\n",
    "\n",
    "        self.n_input_channels = n_input_channels\n",
    "        self.start_kernel = start_kernel\n",
    "        self.depth = depth\n",
    "        self.act_fn_encoder = act_fn_encoder\n",
    "        self.act_fn_decoder = act_fn_decoder\n",
    "        self.act_fn_bottleneck = act_fn_bottleneck\n",
    "        self.up_mode = up_mode\n",
    "        self.max_filter_depth = max_filter_depth\n",
    "        self.do_BN = do_BN\n",
    "        self.bias_conv_layer = bias_conv_layer\n",
    "        self.do_outer_skip = outer_skip\n",
    "        self.do_outer_skip_BN = outer_skip_BN\n",
    "        self.filter_depths = [self.start_kernel * (2 ** i) for i in range(self.depth)]\n",
    "\n",
    "        # Restrict the maximum filter depth to a predefined value\n",
    "        self.filter_depths = [self.max_filter_depth if i > self.max_filter_depth else i for i in self.filter_depths]\n",
    "\n",
    "        # Set up the encoder\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.encoder.append(nn.Sequential(\n",
    "            conv_block(self.n_input_channels, self.start_kernel, activation=self.act_fn_encoder, do_BN=self.do_BN),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            ))\n",
    "\n",
    "        for in_channel, out_channel in zip(self.filter_depths, self.filter_depths[1:]):\n",
    "            self.encoder.append(nn.Sequential(\n",
    "                conv_block(in_channel, out_channel, activation=self.act_fn_encoder, do_BN=self.do_BN),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            ))\n",
    "\n",
    "        # Set up the bottleneck\n",
    "        self.bottleneck = bottleneck(self.filter_depths[-1], self.filter_depths[-1], activation=self.act_fn_bottleneck,\n",
    "                                     do_BN=self.do_BN)\n",
    "\n",
    "        # Set up the decoder\n",
    "        self.decoder = nn.ModuleList()\n",
    "        self.filter_depths_up = list(reversed(self.filter_depths))\n",
    "\n",
    "        for in_channel, out_channel in zip(self.filter_depths_up[:-1], self.filter_depths_up[1:]):\n",
    "            self.decoder.append(conv_up_block(in_channel, out_channel, activation=self.act_fn_decoder,\n",
    "                                              up_mode=self.up_mode, do_BN=self.do_BN))\n",
    "        self.decoder.append(upconv(self.filter_depths_up[-1], self.filter_depths_up[-1], up_mode))\n",
    "\n",
    "        # Set up the final layer of the decoder\n",
    "        self.last_layer = conv3x3(self.start_kernel, 1, bias=self.bias_conv_layer)\n",
    "\n",
    "        # Skip connection\n",
    "        self.skipconnect = SkipConnection()\n",
    "\n",
    "        # Batch normalization added to the long residual skip connection\n",
    "        if self.do_outer_skip:\n",
    "            self.layer_outer_skip = nn.ModuleList()\n",
    "            if self.do_outer_skip_BN:\n",
    "                self.layer_outer_skip.append(nn.BatchNorm2d(1))\n",
    "            self.layer_outer_skip.append(SkipConnection())\n",
    "\n",
    "    def forward(self, x, dem):\n",
    "        skip_connections = []\n",
    "        x = torch.cat((x, dem), dim=1)\n",
    "        out = x\n",
    "\n",
    "        # Encoder (save intermediate outputs for skip connections)\n",
    "        for index, layer in enumerate(self.encoder):\n",
    "            layer_conv = layer[:-1]  # all layers before the pooling layer (at depth index)\n",
    "            layer_pool = layer[-1]   # pooling layer (at depth index)\n",
    "\n",
    "            out_before_pool = layer_conv(out)\n",
    "            skip_connections.append(out_before_pool)\n",
    "            out = layer_pool(out_before_pool)\n",
    "\n",
    "        # Bottleneck\n",
    "        out = self.bottleneck(out)\n",
    "\n",
    "        # Decoder + skip connections\n",
    "        index_max = len(self.decoder) - 1\n",
    "        for index, layer in enumerate(self.decoder):\n",
    "            if index <= index_max - 1:\n",
    "                layer_upconv = layer[0]  # upconv layer\n",
    "                layer_conv = layer[1::]  # all other layers (conv, batchnorm, activation)\n",
    "\n",
    "                out_temp = layer_upconv(out)\n",
    "                out = self.skipconnect(skip_connections[-1 - index], out_temp)\n",
    "                out = layer_conv(out)\n",
    "            else:\n",
    "                out_temp = layer(out)   # upconv of last layer\n",
    "                out = self.skipconnect(skip_connections[-1 - index], out_temp)\n",
    "\n",
    "        # Last layer of the decoder\n",
    "        out = self.last_layer(out)\n",
    "\n",
    "        # Add long residual skip connection\n",
    "        if self.do_outer_skip:\n",
    "            if self.layer_outer_skip.__len__() == 2:\n",
    "                # pipe input through a batch normalization layer before adding it to the output of the last\n",
    "                # decoder layer\n",
    "                bn = self.layer_outer_skip[0]\n",
    "                x_0 = x[:, 0, :, :]       # use channel 0 only\n",
    "                x_0 = x_0.unsqueeze(1)\n",
    "                x = bn(x_0)\n",
    "\n",
    "            # add (batchnorm) input to the output of the last decoder layer\n",
    "            add = self.layer_outer_skip[-1]\n",
    "            x_0 = x[:, 0, :, :]\n",
    "            x_0 = x_0.unsqueeze(1)\n",
    "\n",
    "            out = add(x_0, out)  # use channel 0 only\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86460e84",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bffd0d-ba63-4771-b41d-dd946b04aa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load previous model\n",
    "model = UNet()\n",
    "model.load_state_dict(torch.load('noisemodelv4.2_20epochs'))\n",
    "model.to('cuda')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284e8a8e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "starting epoch 0\n",
      "training loss: 0.11982080505127234\n",
      "validation loss: 0.11926767666837279\n",
      "\n",
      "starting epoch 1\n",
      "training loss: 0.11135180603271715\n",
      "validation loss: 0.11405609532843121\n",
      "\n",
      "starting epoch 2\n",
      "training loss: 0.11161677636599404\n",
      "validation loss: 0.11145757083746084\n",
      "\n",
      "starting epoch 3\n",
      "training loss: 0.10942747268544115\n",
      "validation loss: 0.10778775227916353\n",
      "\n",
      "starting epoch 4\n",
      "training loss: 0.10945549892652222\n",
      "validation loss: 0.108294211708429\n",
      "\n",
      "starting epoch 5\n",
      "training loss: 0.1086692194083703\n",
      "validation loss: 0.11464484665048759\n",
      "\n",
      "starting epoch 6\n",
      "training loss: 0.10618867461015596\n",
      "validation loss: 0.11329941164501046\n",
      "\n",
      "starting epoch 7\n",
      "training loss: 0.1072774933552776\n",
      "validation loss: 0.11335938119224574\n",
      "\n",
      "starting epoch 8\n",
      "training loss: 0.10669244917776548\n",
      "validation loss: 0.10714403757040647\n",
      "\n",
      "starting epoch 9\n",
      "training loss: 0.10768131626910728\n",
      "validation loss: 0.11185458278121697\n",
      "\n",
      "starting epoch 10\n",
      "training loss: 0.1040926513165108\n",
      "validation loss: 0.10676630560861804\n",
      "\n",
      "starting epoch 11\n",
      "training loss: 0.10333277745313209\n",
      "validation loss: 0.11133061170068617\n",
      "\n",
      "starting epoch 12\n",
      "training loss: 0.10441692263291838\n",
      "validation loss: 0.10771619252961112\n",
      "\n",
      "starting epoch 13\n",
      "training loss: 0.1034013516297524\n",
      "validation loss: 0.11152696100931545\n",
      "\n",
      "starting epoch 14\n",
      "training loss: 0.10470283581488653\n",
      "validation loss: 0.11065116055099897\n",
      "\n",
      "starting epoch 15\n",
      "training loss: 0.10354649124616563\n",
      "validation loss: 0.10786662527147961\n",
      "\n",
      "starting epoch 16\n",
      "training loss: 0.10085454239335959\n",
      "validation loss: 0.10945448815328519\n",
      "\n",
      "starting epoch 17\n",
      "training loss: 0.10263479613139694\n",
      "validation loss: 0.11258816002691033\n",
      "\n",
      "starting epoch 18\n",
      "training loss: 0.10332730360403551\n",
      "validation loss: 0.11112317649818117\n",
      "\n",
      "starting epoch 19\n",
      "training loss: 0.10437030436075193\n",
      "validation loss: 0.109046878619994\n",
      "\n",
      "starting epoch 20\n",
      "training loss: 0.10249423876553561\n",
      "validation loss: 0.11276294056658454\n",
      "\n",
      "starting epoch 21\n",
      "training loss: 0.1020773438665054\n",
      "validation loss: 0.11106880898685785\n",
      "\n",
      "starting epoch 22\n",
      "training loss: 0.10069855070605173\n",
      "validation loss: 0.1117150554594151\n",
      "\n",
      "starting epoch 23\n",
      "training loss: 0.102969183051127\n",
      "validation loss: 0.10833852052220751\n",
      "\n",
      "starting epoch 24\n",
      "training loss: 0.1022944084545345\n",
      "validation loss: 0.10942911783215796\n",
      "\n",
      "starting epoch 25\n",
      "training loss: 0.10190858575017238\n",
      "validation loss: 0.11064431715774144\n",
      "\n",
      "starting epoch 26\n",
      "training loss: 0.10218080016817584\n",
      "validation loss: 0.10744997249542355\n",
      "\n",
      "starting epoch 27\n",
      "training loss: 0.10155395144721581\n",
      "validation loss: 0.11124285732935939\n",
      "\n",
      "starting epoch 28\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Define optimizer\n",
    "model = UNet()\n",
    "model.to('cuda') # run on gpu\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0002, weight_decay=0.02) # set learning rate\n",
    "loss_fn   = nn.L1Loss() # MAE loss function, doesn't penalize outliers as much as MSE\n",
    "epochs = 50\n",
    "quantile = 0.9 # full loss computed for pixels with magnitude above this quantile \n",
    "stable_scalar = 1 # scalar for devaluing pixels with magnitude below quantile in loss calc\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'\\nstarting epoch {epoch}')\n",
    "    epoch_loss=[]\n",
    "    val_temp_loss = []\n",
    "    \n",
    "    if epoch == 10:\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001) # reduce loss as given epoch\n",
    "    \n",
    "    #loop through training data \n",
    "    for (sample, signal_target, noise_target, era5_noise, dem, era5_corr, hp_corr) in train_loader:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = torch.clamp(model(sample.to('cuda'), dem.to('cuda')), -1, 1) # Generate noise predictions\n",
    "        \n",
    "        # isolate high-signal areas for loss calculation\n",
    "        # find quantile values for given batch of images\n",
    "        q = signal_target.to('cuda').abs().flatten(1, 3).quantile(dim=1, q=quantile, keepdim=True) \n",
    "        # scale down target values in pixels with magnitude below quantile for loss calc\n",
    "        signal_target_high = torch.where(signal_target.to('cuda').abs()>q.to('cuda')[:, None, None], \n",
    "                                         signal_target.to('cuda'), signal_target.to('cuda')*stable_scalar)\n",
    "        # calculate predicted signals \n",
    "        signal_pred = sample.to('cuda')-out.to('cuda')\n",
    "        # scale down predicted signal values in pixels with magnitude below quantile for loss calc\n",
    "        signal_pred_high = torch.where(signal_target.to('cuda').abs()>q.to('cuda')[:, None, None], \n",
    "                                       signal_pred.to('cuda'), signal_pred.to('cuda')*stable_scalar)\n",
    "        \n",
    "        loss = loss_fn(signal_pred_high.to('cuda'), signal_target_high.to('cuda')) # calculate loss \n",
    "        epoch_loss.append(loss.item()) # add batch loss to epoch loss list\n",
    "        \n",
    "        loss.backward() #Propagate the gradients in backward pass\n",
    "        optimizer.step() \n",
    "\n",
    "    train_loss.append(np.mean(epoch_loss))\n",
    "    print(f'training loss: {np.mean(epoch_loss)}')\n",
    "    \n",
    "    # run model on validation data \n",
    "    for (sample, signal_target, noise_target, era5_noise, dem, era5_corr, hp_corr) in val_loader:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            out = torch.clamp(model(sample.to('cuda'), dem.to('cuda')), -1, 1) #Generate predictions using the model\n",
    "            \n",
    "            # isolate high-signal areas for loss calculation\n",
    "            q = signal_target.to('cuda').abs().flatten(1, 3).quantile(dim=1, q=quantile, keepdim=True)\n",
    "            signal_target_high = torch.where(signal_target.to('cuda').abs()>q.to('cuda')[:, None, None], \n",
    "                                         signal_target.to('cuda'), signal_target.to('cuda')*stable_scalar)   \n",
    "            signal_pred = sample.to('cuda')-out.to('cuda')\n",
    "            signal_pred_high = torch.where(signal_target.to('cuda').abs()>q.to('cuda')[:, None, None], \n",
    "                                       signal_pred.to('cuda'), signal_pred.to('cuda')*stable_scalar)\n",
    "            \n",
    "            loss = loss_fn(signal_pred_high.to('cuda'), signal_target_high.to('cuda')) #Loss/error\n",
    "            val_temp_loss.append(loss.item())\n",
    "    \n",
    "    val_loss.append(np.mean(val_temp_loss))\n",
    "    print(f'validation loss: {np.mean(val_temp_loss)}')\n",
    "    \n",
    "    if (epoch+1)%5 == 0: \n",
    "        # save model\n",
    "        torch.save(model.state_dict(), f'noisemodelv4.3_{epoch+1}epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324d6334",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Examine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640dbc4c-89a7-4cdf-83ee-7c926965c759",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1637d6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot loss over all epochs\n",
    "f, ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(train_loss, label='training')\n",
    "ax.plot(val_loss, label='validation')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('L1 loss')\n",
    "ax.set_title('Loss')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8c5546",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(dataset = val_data, batch_size=1, shuffle=True) #change batch size\n",
    "\n",
    "num_images = 5\n",
    "quantile = 0.90\n",
    "\n",
    "for i, (sample, signal_target, noise_target, era5_noise, dem, era5_corr, hp_corr) in enumerate(val_loader):\n",
    "    if i < num_images:\n",
    "        with torch.no_grad():\n",
    "            noise = model(sample.to('cuda'), dem.to('cuda')) #Generate predictions using the model\n",
    "            signal = torch.clamp(sample.to('cpu') - noise.to('cpu'), -1, 1)\n",
    "            q = signal_target.to('cuda').abs().flatten(1, 3).quantile(dim=1, q=quantile, keepdim=True)\n",
    "            signal_target_high = signal_target.to('cuda').abs()>q.to('cuda')[:, None, None]\n",
    "            \n",
    "            \n",
    "            f, ax = plt.subplots(2, 3, figsize=(15,10))\n",
    "            ax[0][0].imshow(sample.squeeze(), cmap='RdBu', vmin=-2, vmax=2) \n",
    "            ax[0][0].set_title('original interferogram')\n",
    "            ax[0][1].imshow(noise.squeeze().to('cpu'), cmap='RdBu', vmin=-2, vmax=2)\n",
    "            ax[0][1].set_title('predicted noise')\n",
    "            ax[0][2].imshow((sample.squeeze()-signal_target.squeeze()), cmap='RdBu', vmin=-2, vmax=2)\n",
    "            ax[0][2].set_title('true noise')\n",
    "            ax[1][1].imshow(signal.squeeze(), cmap='RdBu', vmin=-2, vmax=2)\n",
    "            ax[1][1].set_title('predicted signal')\n",
    "            ax[1][2].imshow(signal_target.squeeze(), cmap='RdBu', vmin=-2, vmax=2)\n",
    "            ax[1][2].set_title('true signal')\n",
    "            ax[1][0].imshow(signal_target_high.squeeze().to('cpu'))\n",
    "            ax[1][0].set_title('high loss areas')\n",
    "            plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bd2a35-e521-415d-a787-65672ae0a01c",
   "metadata": {},
   "source": [
    "## Correction comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71057585",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_ssim = dataset(val_list, val_signal_dir, val_noise_dir, val_dem_dir, val_era5_dir, transform=my_transforms, \n",
    "                        blurnoise=True)\n",
    "train_data_ssim = dataset(train_list, train_signal_dir, train_noise_dir, train_dem_dir, train_era5_dir, transform=my_transforms, \n",
    "                        blurnoise=True)\n",
    "val_loader_ssim = torch.utils.data.DataLoader(dataset = val_data_ssim, batch_size=1, shuffle=False)\n",
    "train_loader_ssim = torch.utils.data.DataLoader(dataset = train_data_ssim, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa31b542-bfdd-4373-9f9a-564c9031f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine corrections\n",
    "num_images = 5\n",
    "\n",
    "for i, (sample, signal_target, noise_target, era5_noise, dem, era5_corr, hp_corr) in enumerate(val_loader_ssim):\n",
    "    if i < num_images:\n",
    "            noise_pred = model(sample.to('cuda'), dem.to('cuda')) #Generate predictions using the model\n",
    "            signal_pred = torch.clamp(sample.to('cpu') - noise_pred.to('cpu'), -1, 1)\n",
    "            f, ax = plt.subplots(2, 3, figsize=(10,7))\n",
    "            ax[0, 0].imshow(sample.squeeze(), cmap='RdBu', vmin=-2, vmax=2) \n",
    "            ax[0, 0].set_title('training')\n",
    "            ax[0, 1].imshow(signal_target.squeeze(), cmap='RdBu', vmin=-2, vmax=2)\n",
    "            ax[0, 1].set_title('target signal')\n",
    "            ax[0, 2].imshow((sample.squeeze()-signal_target.squeeze()), cmap='RdBu', vmin=-2, vmax=2)\n",
    "            ax[0, 2].set_title('target noise')\n",
    "            \n",
    "            ax[1, 0].imshow(signal_pred.detach().squeeze(), cmap='RdBu', vmin=-2, vmax=2)\n",
    "            ax[1, 0].set_title('model corrected')\n",
    "            ax[1, 1].imshow(era5_corr.squeeze(), cmap='RdBu', vmin=-2, vmax=2)\n",
    "            ax[1, 1].set_title('ERA5 corrected')\n",
    "            ax[1, 2].imshow(hp_corr.squeeze(), cmap='RdBu', vmin=-2, vmax=2)\n",
    "            ax[1, 2].set_title('hp filter corrected')\n",
    "            f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d889683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssim_lists(model, data_loader):\n",
    "    # Calculate val SSIM \n",
    "    ssim_list_uncorrected = []\n",
    "    ssim_list_model_corrected = []\n",
    "    ssim_list_era5_corrected = []\n",
    "    ssim_list_hp_corrected = []\n",
    "    \n",
    "    for i, (sample, signal_target, noise_target, era5_noise, dem, era5_corr, hp_corr) in enumerate(data_loader):\n",
    "        # uncorrected SSIM\n",
    "        ssim_value_uncorrected = ssim(sample.squeeze().detach().numpy(), signal_target.squeeze().detach().numpy(),\n",
    "                         gaussian_weights=True)\n",
    "        ssim_list_uncorrected.append(ssim_value_uncorrected)\n",
    "    \n",
    "        # model corrected SSIM\n",
    "        noise = model(sample.to('cuda'), dem.to('cuda')) #Generate predictions using the model\n",
    "        signal = torch.clamp(sample.to('cpu') - noise.to('cpu'), -1, 1)\n",
    "        ssim_value_model_corrected = ssim(signal.squeeze().detach().numpy(), signal_target.squeeze().detach().numpy(),\n",
    "                         gaussian_weights=True)\n",
    "        ssim_list_model_corrected.append(ssim_value_model_corrected)\n",
    "    \n",
    "        # era5 corrected SSIM\n",
    "        ssim_value_era5_corrected = ssim(era5_corr.squeeze().numpy(), signal_target.squeeze().numpy(),\n",
    "                         gaussian_weights=True)\n",
    "        ssim_list_era5_corrected.append(ssim_value_era5_corrected)\n",
    "    \n",
    "        # hp filter corrected SSIM\n",
    "        ssim_value_hp_corrected = ssim(hp_corr.squeeze().numpy(), signal_target.squeeze().numpy(),\n",
    "                         gaussian_weights=True)\n",
    "        ssim_list_hp_corrected.append(ssim_value_hp_corrected)\n",
    "    \n",
    "    \n",
    "    print('mean ssim before correction:', np.mean(ssim_list_uncorrected),\n",
    "          '\\nmean ssim model correction:', np.mean(ssim_list_model_corrected), \n",
    "          '\\nmean ssim era5 correction:', np.mean(ssim_list_era5_corrected),\n",
    "          '\\nmean ssim high pass filter correction:', np.mean(ssim_list_hp_corrected))\n",
    "    \n",
    "    return ssim_list_uncorrected, ssim_list_model_corrected, ssim_list_era5_corrected, ssim_list_hp_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ace80e-1b9f-4cb1-8d00-90b5f53a7870",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('val data ssim')\n",
    "val_ssim_list_uncorrected, val_ssim_list_model, val_ssim_list_era5, val_ssim_list_hp = ssim_lists(model, val_loader_ssim)\n",
    "print('training data ssim')\n",
    "train_ssim_list_uncorrected, train_ssim_list_model, train_ssim_list_era5, train_ssim_list_hp = ssim_lists(model, train_loader_ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e2689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SNR\n",
    "def rms(tensor):\n",
    "    rms = np.sqrt(np.mean(tensor.squeeze().numpy()**2))\n",
    "    return rms\n",
    "\n",
    "def snr(model, data_loader):\n",
    "    snr_list = []\n",
    "\n",
    "    for i, (sample, signal_target, noise_target, era5_noise, dem, era5_corr, hp_corr) in enumerate(data_loader):\n",
    "        snr_list.append(rms(signal_target)/rms(sample-signal_target))\n",
    "\n",
    "    print('mean snr of images:', np.mean(snr_list))\n",
    "    \n",
    "    return snr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4407742-5fd7-4983-89e4-52ec751755a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_snr_list = snr(model, val_loader_ssim)\n",
    "train_snr_list = snr(model, train_loader_ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72691d04-4376-4ca9-8ec0-9b77c50b4437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_for_plotting(snr_list, ssim_list_uncorrected, ssim_list_model, ssim_list_era5, ssim_list_hp):\n",
    "\n",
    "    roll_count = 200\n",
    "    q_low = 25\n",
    "    q_high = 75\n",
    "\n",
    "    ssim_dict = {'snr': snr_list,\n",
    "                     'ssim_uncorrected':ssim_list_uncorrected,\n",
    "                     'ssim_model':ssim_list_model,\n",
    "                     'ssim_era5':ssim_list_era5, \n",
    "                     'ssim_hp':ssim_list_hp}\n",
    "    ssim_df = pd.DataFrame(ssim_dict)\n",
    "\n",
    "    # uncorrected ssim\n",
    "    ssim_df['ssim_uncorrected_median'] = ssim_df.sort_values(by=['snr']).ssim_uncorrected.rolling(roll_count, center=True).median()\n",
    "    ssim_df[f'ssim_uncorrected_q{q_low}'] = ssim_df.sort_values(by=['snr']).ssim_uncorrected.rolling(roll_count, center=True).quantile(quantile=q_low/100)\n",
    "    ssim_df[f'ssim_uncorrected_q{q_high}'] = ssim_df.sort_values(by=['snr']).ssim_uncorrected.rolling(roll_count, center=True).quantile(quantile=q_high/100)\n",
    "\n",
    "    # model corrected ssim\n",
    "    ssim_df['ssim_model_median'] = ssim_df.sort_values(by=['snr']).ssim_model.rolling(roll_count, center=True).median()\n",
    "    ssim_df[f'ssim_model_q{q_low}'] = ssim_df.sort_values(by=['snr']).ssim_model.rolling(roll_count, center=True).quantile(quantile=q_low/100)\n",
    "    ssim_df[f'ssim_model_q{q_high}'] = ssim_df.sort_values(by=['snr']).ssim_model.rolling(roll_count, center=True).quantile(quantile=q_high/100)\n",
    "\n",
    "    # era5 corrected ssim\n",
    "    ssim_df['ssim_era5_median'] = ssim_df.sort_values(by=['snr']).ssim_era5.rolling(roll_count, center=True).median()\n",
    "    ssim_df[f'ssim_era5_q{q_low}'] = ssim_df.sort_values(by=['snr']).ssim_era5.rolling(roll_count, center=True).quantile(quantile=q_low/100)\n",
    "    ssim_df[f'ssim_era5_q{q_high}'] = ssim_df.sort_values(by=['snr']).ssim_era5.rolling(roll_count, center=True).quantile(quantile=q_high/100)\n",
    "\n",
    "    # era5 corrected ssim\n",
    "    ssim_df['ssim_hp_median'] = ssim_df.sort_values(by=['snr']).ssim_hp.rolling(roll_count, center=True).median()\n",
    "    ssim_df[f'ssim_hp_q{q_low}'] = ssim_df.sort_values(by=['snr']).ssim_hp.rolling(roll_count, center=True).quantile(quantile=q_low/100)\n",
    "    ssim_df[f'ssim_hp_q{q_high}'] = ssim_df.sort_values(by=['snr']).ssim_hp.rolling(roll_count, center=True).quantile(quantile=q_high/100)\n",
    "    \n",
    "    return ssim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc48d7e-e097-4e6c-8a56-c0b193118eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ssim_df=df_for_plotting(val_snr_list, val_ssim_list_uncorrected, val_ssim_list_model, val_ssim_list_era5, val_ssim_list_hp)\n",
    "train_ssim_df=df_for_plotting(train_snr_list, train_ssim_list_uncorrected, train_ssim_list_model, train_ssim_list_era5, train_ssim_list_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1cfd2d-a5e8-4009-bed6-298bf920c535",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "\n",
    "f, ax = plt.subplots(4, 2, figsize=(10,10), sharex=True, sharey=True)\n",
    "\n",
    "# val uncorrected \n",
    "sns.histplot(ax=ax[0, 0], x=val_ssim_df.snr, y=val_ssim_df.ssim_uncorrected, cmap='Oranges', cbar=False, alpha=0)\n",
    "ax[0, 0].set_xscale('log')\n",
    "\n",
    "sns.histplot(ax=ax[0, 0], x=val_ssim_df.snr, y=val_ssim_df.ssim_uncorrected, cmap='Oranges', cbar=True,\n",
    "             bins=30, vmax=50, alpha=0.8)\n",
    "ax[0, 0].set_xscale('log')\n",
    "ax[0, 0].set_ylabel('SSIM')\n",
    "ax[0, 0].set_title('uncorrected images (validation)')\n",
    "\n",
    "sns.lineplot(ax=ax[0, 0], x=val_ssim_df.snr, y=val_ssim_df.ssim_uncorrected_median, size=1, c='k', legend=False, alpha=0.6)\n",
    "sns.lineplot(ax=ax[0, 0], x=val_ssim_df.snr, y=val_ssim_df.ssim_uncorrected_q25, size=1, c='gray', legend=False, alpha=0.6)\n",
    "sns.lineplot(ax=ax[0, 0], x=val_ssim_df.snr, y=val_ssim_df.ssim_uncorrected_q75, size=1, c='gray', legend=False, alpha=0.6)\n",
    "\n",
    "# val model corrected\n",
    "sns.histplot(ax=ax[1, 0], x=val_ssim_df.snr, y=val_ssim_df.ssim_model, cmap='Oranges', cbar=True,\n",
    "             bins=30, vmax=50, alpha=0.8)\n",
    "ax[1, 0].set_xscale('log')\n",
    "ax[1, 0].set_ylabel('SSIM')\n",
    "ax[1, 0].set_title('model correction (validation)')\n",
    "\n",
    "sns.lineplot(ax=ax[1, 0], x=val_ssim_df.snr, y=val_ssim_df.ssim_model_median, size=1, c='k', legend=False, alpha=0.6)\n",
    "sns.lineplot(ax=ax[1, 0], x=val_ssim_df.snr, y=val_ssim_df.ssim_model_q25, size=1, c='gray', legend=False, alpha=0.6)\n",
    "sns.lineplot(ax=ax[1, 0], x=val_ssim_df.snr, y=val_ssim_df.ssim_model_q75, size=1, c='gray', legend=False, alpha=0.6)\n",
    "\n",
    "# val era5 corrected\n",
    "sns.histplot(ax=ax[2, 0], x=val_ssim_df.snr, y=val_ssim_df.ssim_era5, cmap='Oranges', cbar=True,\n",
    "             bins=30, vmax=50, alpha=0.8)\n",
    "ax[2, 0].set_xscale('log')\n",
    "ax[2, 0].set_ylabel('SSIM')\n",
    "ax[2, 0].set_title('ERA5 correction (validation)')\n",
    "\n",
    "sns.lineplot(ax=ax[2, 0], x=val_ssim_df.snr, y=val_ssim_df.ssim_era5_median, size=1, c='k', legend=False, alpha=0.6)\n",
    "sns.lineplot(ax=ax[2, 0], x=val_ssim_df.snr, y=val_ssim_df.ssim_era5_q25, size=1, c='gray', legend=False, alpha=0.6)\n",
    "sns.lineplot(ax=ax[2, 0], x=val_ssim_df.snr, y=val_ssim_df.ssim_era5_q75, size=1, c='gray', legend=False, alpha=0.6)\n",
    "\n",
    "# val hp corrected\n",
    "sns.histplot(ax=ax[3, 0], x=val_ssim_df.snr, y=val_ssim_df.ssim_hp, cmap='Oranges', cbar=True,\n",
    "             bins=30, vmax=50, alpha=0.8)\n",
    "ax[3, 0].set_xscale('log')\n",
    "ax[3, 0].set_xlabel('SNR (signal/atmosphere)')\n",
    "ax[3, 0].set_ylabel('SSIM')\n",
    "ax[3, 0].set_title('high-pass filter correction (validation)')\n",
    "\n",
    "sns.lineplot(ax=ax[3, 0], x=val_ssim_df.snr, y=val_ssim_df.ssim_hp_median, size=1, c='k', legend=False, alpha=0.6)\n",
    "sns.lineplot(ax=ax[3, 0], x=val_ssim_df.snr, y=val_ssim_df.ssim_hp_q25, size=1, c='gray', legend=False, alpha=0.6)\n",
    "sns.lineplot(ax=ax[3, 0], x=val_ssim_df.snr, y=val_ssim_df.ssim_hp_q75, size=1, c='gray', legend=False, alpha=0.6)\n",
    "\n",
    "# train uncorrected \n",
    "sns.histplot(ax=ax[0, 1], x=train_ssim_df.snr, y=train_ssim_df.ssim_uncorrected, cmap='Blues', cbar=True, \n",
    "             bins=30, vmax=100, alpha=0.8)\n",
    "ax[0, 1].set_xscale('log')\n",
    "ax[0, 1].set_title('uncorrected images (training)')\n",
    "\n",
    "sns.lineplot(ax=ax[0, 1], x=train_ssim_df.snr, y=train_ssim_df.ssim_uncorrected_median, size=1, c='k', legend=False, alpha=0.6)\n",
    "sns.lineplot(ax=ax[0, 1], x=train_ssim_df.snr, y=train_ssim_df.ssim_uncorrected_q25, size=1, c='gray', legend=False, alpha=0.6)\n",
    "sns.lineplot(ax=ax[0, 1], x=train_ssim_df.snr, y=train_ssim_df.ssim_uncorrected_q75, size=1, c='gray', legend=False, alpha=0.6)\n",
    "\n",
    "# train model corrected\n",
    "sns.histplot(ax=ax[1, 1], x=train_ssim_df.snr, y=train_ssim_df.ssim_model, cmap='Blues', cbar=True, \n",
    "             bins=30, vmax=100, alpha=0.8)\n",
    "ax[1, 1].set_xscale('log')\n",
    "ax[1, 1].set_title('model correction (training)')\n",
    "f.tight_layout()\n",
    "\n",
    "sns.lineplot(ax=ax[1, 1], x=train_ssim_df.snr, y=train_ssim_df.ssim_model_median, size=1, c='k', legend=False, alpha=0.6)\n",
    "sns.lineplot(ax=ax[1, 1], x=train_ssim_df.snr, y=train_ssim_df.ssim_model_q25, size=1, c='gray', legend=False, alpha=0.6)\n",
    "sns.lineplot(ax=ax[1, 1], x=train_ssim_df.snr, y=train_ssim_df.ssim_model_q75, size=1, c='gray', legend=False, alpha=0.6)\n",
    "\n",
    "# train era5 corrected\n",
    "sns.histplot(ax=ax[2, 1], x=train_ssim_df.snr, y=train_ssim_df.ssim_era5, cmap='Blues', cbar=True, \n",
    "             bins=30, vmax=100, alpha=0.8)\n",
    "ax[2, 1].set_xscale('log')\n",
    "ax[2, 1].set_title('ERA5 correction (training)')\n",
    "f.tight_layout()\n",
    "\n",
    "sns.lineplot(ax=ax[2, 1], x=train_ssim_df.snr, y=train_ssim_df.ssim_era5_median, size=1, c='k', legend=False, alpha=0.6)\n",
    "sns.lineplot(ax=ax[2, 1], x=train_ssim_df.snr, y=train_ssim_df.ssim_era5_q25, size=1, c='gray', legend=False, alpha=0.6)\n",
    "sns.lineplot(ax=ax[2, 1], x=train_ssim_df.snr, y=train_ssim_df.ssim_era5_q75, size=1, c='gray', legend=False, alpha=0.6)\n",
    "\n",
    "# train hp corrected\n",
    "sns.histplot(ax=ax[3, 1], x=train_ssim_df.snr, y=train_ssim_df.ssim_hp, cmap='Blues', cbar=True, \n",
    "             bins=30, vmax=100, alpha=0.8)\n",
    "ax[3, 1].set_xscale('log')\n",
    "ax[3, 1].set_xlabel('SNR (signal/atmosphere)')\n",
    "ax[3, 1].set_title('high-pass filter correction (training)')\n",
    "f.tight_layout()\n",
    "\n",
    "sns.lineplot(ax=ax[3, 1], x=train_ssim_df.snr, y=train_ssim_df.ssim_hp_median, size=1, c='k', legend=False, alpha=0.6)\n",
    "sns.lineplot(ax=ax[3, 1], x=train_ssim_df.snr, y=train_ssim_df.ssim_hp_q25, size=1, c='gray', legend=False, alpha=0.6)\n",
    "sns.lineplot(ax=ax[3, 1], x=train_ssim_df.snr, y=train_ssim_df.ssim_hp_q75, size=1, c='gray', legend=False, alpha=0.6)\n",
    "\n",
    "\n",
    "plt.savefig('SSIMv1.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6670ef-c044-4c6f-a0ad-b298c27a021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# violin plots \n",
    "ssim_labels = ['ssim_uncorrected',  'ssim_model', 'ssim_era5', 'ssim_hp']\n",
    "val_ssim_long = pd.melt(val_ssim_df[ssim_labels], value_vars=ssim_labels, var_name='corr_type', value_name='ssim')\n",
    "val_ssim_long['dataset'] = 'val'\n",
    "\n",
    "ssim_labels = ['ssim_uncorrected',  'ssim_model', 'ssim_era5', 'ssim_hp']\n",
    "train_ssim_long = pd.melt(train_ssim_df[ssim_labels], value_vars=ssim_labels, var_name='corr_type', value_name='ssim')\n",
    "train_ssim_long['dataset'] = 'train'\n",
    "\n",
    "all_ssim_long = pd.concat([train_ssim_long, val_ssim_long])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9b7961-ea2d-4a69-91d4-bdf80f0d52e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "sns.violinplot(ax=ax, data=all_ssim_long, x=\"corr_type\", y=\"ssim\", hue='dataset')\n",
    "ax.set_xticklabels(['uncorrected', 'CNN', 'ERA5', 'gaussian filter'])\n",
    "ax.set_xlabel('correction type')\n",
    "ax.set_ylabel('SSIM')\n",
    "plt.savefig('SSIM_violin.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e0d908-f63f-415a-8291-e118666bab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if data are normally distributed\n",
    "print('val uncorrected: ', stats.kstest(val_ssim_df['ssim_uncorrected'].values, stats.norm.cdf))\n",
    "print('val model: ', stats.kstest(val_ssim_df['ssim_model_corrected'].values, stats.norm.cdf))\n",
    "print('val era5: ', stats.kstest(val_ssim_df['ssim_era5_corrected'].values, stats.norm.cdf))\n",
    "print('val hp: ', stats.kstest(val_ssim_df['ssim_hp_corrected'].values, stats.norm.cdf))\n",
    "\n",
    "#they are not even close to normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c982ab1-2409-4d61-9f0f-806a659ca9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wilcoxon signed rank test to compare paired samples\n",
    "stats.wilcoxon(val_ssim_df['ssim_uncorrected'].values, val_ssim_df['ssim_model_corrected'].values, nan_policy='omit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9442eb23-d5df-476d-acde-6e7e15146d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.wilcoxon(val_ssim_df['ssim_model_corrected'].values, val_ssim_df['ssim_era5_corrected'].values, nan_policy='omit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2e7160-35b4-40f8-8e3f-74e2d4a0e756",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.wilcoxon(val_ssim_df['ssim_model_corrected'].values, val_ssim_df['ssim_hp_corrected'].values, nan_policy='omit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3eb0f3-54a5-4e95-a00a-f745a3c2c133",
   "metadata": {},
   "source": [
    "## Visualize feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f84cc6-e539-4231-8e5e-558efbe2f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize feature maps\n",
    "\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "cnn_names = ['cnn1', 'cnn2', 'cnn3','cnn4','cnn5', 'cnn6', 'cnn7', 'cnn8'] \n",
    "cnn_vars = [model.cnn1, model.cnn2, model.cnn3, model.cnn4, model.cnn5,\n",
    "            model.cnn6, model.cnn7, model.cnn8]\n",
    "\n",
    "\n",
    "def plot_feature(cnn_vars, cnn_names, num_images=1):\n",
    "    for i, (sample, signal_target, noise_target, dem) in enumerate(val_loader):\n",
    "        if i<num_images:\n",
    "            for j, cnn_name in enumerate(cnn_names):\n",
    "                cnn = cnn_vars[j]\n",
    "                cnn.register_forward_hook(get_activation(cnn_name))\n",
    "                output = model(sample.to('cuda'), dem.to('cuda'))\n",
    "\n",
    "                act = activation[cnn_name].squeeze()\n",
    "                act1 = act[0:15,:,:].sum(dim=0, keepdim=True).squeeze()\n",
    "                act2 = act[16:31,:,:].sum(dim=0, keepdim=True).squeeze()\n",
    "                act3 = act[32:47,:,:].sum(dim=0, keepdim=True).squeeze()\n",
    "                act4 = act[48:63,:,:].sum(dim=0, keepdim=True).squeeze()\n",
    "\n",
    "                fig, ax = plt.subplots(1, 5, figsize=(19,5))\n",
    "                #ax[0].imshow(dem.squeeze().to('cpu'), cmap='Greys')\n",
    "                ax[0].imshow(sample.squeeze().to('cpu'), cmap='RdBu')\n",
    "                ax[0].set_title('original image')\n",
    "                ax[1].imshow(act1.to('cpu'))\n",
    "                ax[1].set_title(f'{cnn_name} feature map')\n",
    "                ax[2].imshow(act2.to('cpu'))\n",
    "                ax[2].set_title(f'{cnn_name} feature map')\n",
    "                ax[3].imshow(act3.to('cpu'))\n",
    "                ax[3].set_title(f'{cnn_name} feature map')\n",
    "                ax[4].imshow(act4.to('cpu'))\n",
    "                ax[4].set_title(f'{cnn_name} feature map')\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "val_loader = torch.utils.data.DataLoader(dataset = val_data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760c345f-31a2-4e46-92b4-a22f51fa5c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature(cnn_vars, cnn_names, num_images=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:notebook] *",
   "language": "python",
   "name": "conda-env-notebook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
