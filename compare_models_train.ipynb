{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ba9a302-3cc9-4393-9f0e-2ac159f12ca2",
   "metadata": {},
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4223fc81-5d1b-4c0c-aec2-f785ada78caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import torch\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import math\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import random\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d48c83d-6911-4d13-b741-d37524e47d31",
   "metadata": {},
   "source": [
    "## Set up data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f962aeb-f4dd-4fe1-9b96-4894155e07f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths\n",
    "main_dir = '/home/jovyan/InSAR_denoising_CNN'\n",
    "train_signal_dir = f'{main_dir}/train_subsets_v2/veloc/'\n",
    "train_noise_dir = f'{main_dir}/train_subsets_v2/int/'\n",
    "train_dem_dir = f'{main_dir}/train_subsets_v2/dem/'\n",
    "train_era5_dir = f'{main_dir}/train_subsets_v2/era5/'\n",
    "\n",
    "val_signal_dir = f'{main_dir}/val_subsets_v2/veloc/'\n",
    "val_noise_dir = f'{main_dir}/val_subsets_v2/int/'\n",
    "val_dem_dir = f'{main_dir}/val_subsets_v2/dem/'\n",
    "val_era5_dir = f'{main_dir}/val_subsets_v2/era5/'\n",
    "\n",
    "# list files\n",
    "train_signal_fns = os.listdir(train_signal_dir)\n",
    "train_noise_fns = os.listdir(train_noise_dir)\n",
    "train_dem_fns = os.listdir(train_dem_dir)\n",
    "train_era5_fns = os.listdir(train_era5_dir)\n",
    "\n",
    "val_signal_fns = os.listdir(val_signal_dir)\n",
    "val_noise_fns = os.listdir(val_noise_dir)\n",
    "val_dem_fns = os.listdir(val_dem_dir)\n",
    "val_era5_fns = os.listdir(val_era5_dir)\n",
    "\n",
    "# exclude non tif files, e.g. metadata\n",
    "def list_tifs(my_fns):\n",
    "    my_list = []\n",
    "    for i in my_fns:\n",
    "        if i[-4:] == '.tif':\n",
    "            my_list.append(i)\n",
    "    return my_list\n",
    "\n",
    "train_signal_list = list_tifs(train_signal_fns)\n",
    "train_noise_list = list_tifs(train_noise_fns)\n",
    "train_dem_list = list_tifs(train_dem_fns)\n",
    "train_era5_list = list_tifs(train_era5_fns)\n",
    "\n",
    "val_signal_list = list_tifs(val_signal_fns)\n",
    "val_noise_list = list_tifs(val_noise_fns)\n",
    "val_dem_list = list_tifs(val_dem_fns)\n",
    "val_era5_list = list_tifs(val_era5_fns)\n",
    "\n",
    "# create training list of only scenes shared in all necessary dirs\n",
    "train_list = []\n",
    "for fn in train_signal_list:\n",
    "    if fn in train_noise_list and fn in train_dem_list and fn in train_era5_list:\n",
    "        train_list.append(fn)\n",
    "        \n",
    "val_list = []\n",
    "for fn in val_signal_list:\n",
    "    if fn in val_noise_list and fn in val_dem_list and fn in val_era5_list:\n",
    "        val_list.append(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0241580-4c09-41e4-a9fa-dc900c45bc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transforms\n",
    "my_transforms = transforms.Compose([\n",
    "    transforms.ToTensor() #because label is also an image that needs to match, can't do any flipping\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1361a8-925a-4871-b519-91aa54786536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset \n",
    "class dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_list, signal_dir, noise_dir, dem_dir, era5_dir, transform=None, \n",
    "                 norm=True, center=True, invert=False, blurnoise=False):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.signal_dir = signal_dir\n",
    "        self.noise_dir = noise_dir\n",
    "        self.dem_dir = dem_dir\n",
    "        self.era5_dir = era5_dir\n",
    "        self.norm = norm\n",
    "        self.center = center\n",
    "        self.invert = invert\n",
    "        self.blurnoise = blurnoise\n",
    "        \n",
    "    #dataset length\n",
    "    def __len__(self):\n",
    "        self.filelength = len(self.file_list)\n",
    "        return self.filelength\n",
    "    \n",
    "    #load images\n",
    "    def __getitem__(self,idx):\n",
    "        signal_path = self.signal_dir+self.file_list[idx]\n",
    "        noise_path = self.noise_dir+self.file_list[idx]\n",
    "        dem_path = self.dem_dir+self.file_list[idx]\n",
    "        era5_path = self.era5_dir+self.file_list[idx]\n",
    "        \n",
    "        signal = self.transform(Image.open(signal_path))\n",
    "        noise = self.transform(Image.open(noise_path))\n",
    "        dem = self.transform(Image.open(dem_path))\n",
    "        era5 = self.transform(Image.open(era5_path))\n",
    "        \n",
    "        # Generate era5 noise estimates\n",
    "        era5 = era5*(0.05546576/12.5663706) # convert phase to displacement\n",
    "        era5 = (noise-(era5*-1)) \n",
    "        \n",
    "        # Blur noise\n",
    "        if self.blurnoise == True: # blur noise to mitigate noise from non atmospheric sources\n",
    "            gblur = transforms.GaussianBlur(kernel_size=(7, 7), sigma=5)\n",
    "            noise = gblur(noise)\n",
    "        \n",
    "        # Generate scaled training images\n",
    "        scalar = np.round(np.random.lognormal(0.05, 1.), 3)\n",
    "        signal = signal*scalar\n",
    "        train = noise+signal\n",
    "        \n",
    "        # Set era reference point\n",
    "        ref_index = signal.abs().argmin().item() # location of lowest signal in velocity map\n",
    "        corr_diff = (train.flatten()[ref_index] - era5.flatten()[ref_index]).item()\n",
    "        era5 = era5+corr_diff \n",
    "        \n",
    "        # correct train\n",
    "        era5_corr = train-era5 #produce era5 corrected train image\n",
    "        \n",
    "        # correct hp\n",
    "        hp_filter = transforms.GaussianBlur(kernel_size=(25, 25), sigma=3)\n",
    "        train_filtered = hp_filter(train)\n",
    "        hp_corr = train - train_filtered\n",
    "        \n",
    "        # normalization between -1 and 1 as in Zhao et al. https://doi.org/10.1016/j.isprsjprs.2021.08.009\n",
    "        if self.norm == True:\n",
    "            if train.min() < signal.min():\n",
    "                norm_min = train.min()\n",
    "            else:\n",
    "                norm_min = signal.min()\n",
    "                \n",
    "            if train.max() > signal.max():\n",
    "                norm_max = train.max()\n",
    "            else:\n",
    "                norm_max = signal.max()\n",
    "            \n",
    "            signal = 2*(((signal-norm_min)/(norm_max-norm_min)))-1\n",
    "            noise  = 2*(((noise-(noise.min()))/(noise.max()-(noise.min()))))-1\n",
    "            dem = 2*(((dem-dem.min())/(dem.max()-dem.min())))-1\n",
    "            train = 2*(((train-norm_min)/(norm_max-norm_min)))-1\n",
    "            era5 = 2*(((era5-era5.min())/(era5.max()-era5.min())))-1\n",
    "            era5_corr = 2*(((era5_corr-norm_min)/(norm_max-norm_min)))-1\n",
    "            hp_corr = 2*(((hp_corr-norm_min)/(norm_max-norm_min)))-1\n",
    "        \n",
    "        if self.center == True: # center target images on 0 \n",
    "            center_median = signal.median()\n",
    "            train = train-center_median\n",
    "            signal = signal-center_median\n",
    "            era5_corr = era5_corr-center_median\n",
    "            hp_corr = hp_corr-center_median\n",
    "         \n",
    "        # invert images to remove bias towards negative signal\n",
    "        if self.invert == True:\n",
    "            if random.random() < 0.5:\n",
    "                train = train*-1\n",
    "                signal = signal*-1\n",
    "                noise = noise*-1\n",
    "                era5 = era5*-1\n",
    "                era5_corr = era5_corr*-1\n",
    "                hp_corr = hp_corr*-1\n",
    "        \n",
    "        return train, signal, noise, era5, dem, era5_corr, hp_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c126af0-3575-4a8b-b2d3-d249dd7d8ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "val_data = dataset(val_list, signal_dir, noise_dir, dem_dir, era5_dir, transform=my_transforms, \n",
    "                        invert=False, blurnoise=True)\n",
    "train_data = dataset(train_list, signal_dir, noise_dir, dem_dir, era5_dir, transform=my_transforms, \n",
    "                        invert=False, blurnoise=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset = val_data, batch_size=1, shuffle=False)\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7366ab92-9182-4661-b666-a0b970349d01",
   "metadata": {},
   "source": [
    "## Define networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ed1ffe-056f-4d9b-ad15-75b610915fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DnCNN_noise(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network model for InSAR denoising adapted from Rouet-Leduc et al., 2021\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        kernel_size=3\n",
    "        padding=1\n",
    "        features=64\n",
    "        channels=2\n",
    "        \n",
    "        # Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "        # Convolution 2\n",
    "        self.cnn2 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "        # Convolution 3\n",
    "        self.cnn3 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "        # Convolution 4\n",
    "        self.cnn4 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "        # Convolution 5\n",
    "        self.cnn5 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=5, dilation=5)\n",
    "        \n",
    "         # Convolution 6\n",
    "        self.cnn6 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=5, dilation=5)\n",
    "        \n",
    "        # Convolution 7\n",
    "        self.cnn7 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "        # Convolution 8\n",
    "        self.cnn8 = nn.Conv2d(in_channels=features, out_channels=1, kernel_size=kernel_size, padding=padding)\n",
    "\n",
    "    def forward(self, x, dem):                \n",
    "        # Set 1\n",
    "        out = F.elu(self.cnn1(torch.cat((x, dem), dim=1)), inplace=True) \n",
    "        \n",
    "        # Set 2\n",
    "        out = F.elu(self.cnn2(out), inplace=True) \n",
    "        \n",
    "        # Set 3\n",
    "        out = F.elu(self.cnn3(out), inplace=True)  \n",
    "        \n",
    "        # Set 4\n",
    "        out = F.elu(self.cnn4(out), inplace=True) \n",
    "        \n",
    "        # Set 5\n",
    "        out = F.elu(self.cnn5(out), inplace=True)\n",
    "        \n",
    "        # Set 6\n",
    "        out = F.elu(self.cnn6(out), inplace=True)\n",
    "        \n",
    "        # Set 7\n",
    "        out = F.elu(self.cnn7(out), inplace=True)\n",
    "\n",
    "        # Set 8\n",
    "        out = self.cnn8(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b7599d-af07-4d09-b3f6-41d635dea43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DnCNN_noise_era5(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network model for InSAR denoising adapted from Rouet-Leduc et al., 2021\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        kernel_size=3\n",
    "        padding=1\n",
    "        features=64\n",
    "        channels=3\n",
    "        \n",
    "        # Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "        # Convolution 2\n",
    "        self.cnn2 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "        # Convolution 3\n",
    "        self.cnn3 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "        # Convolution 4\n",
    "        self.cnn4 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "        # Convolution 5\n",
    "        self.cnn5 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=5, dilation=5)\n",
    "        \n",
    "         # Convolution 6\n",
    "        self.cnn6 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=5, dilation=5)\n",
    "        \n",
    "        # Convolution 7\n",
    "        self.cnn7 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "        # Convolution 8\n",
    "        self.cnn8 = nn.Conv2d(in_channels=features, out_channels=1, kernel_size=kernel_size, padding=padding)\n",
    "\n",
    "    def forward(self, x, era5, dem):                \n",
    "        # Set 1\n",
    "        out = F.elu(self.cnn1(torch.cat((x, era5, dem), dim=1)), inplace=True) \n",
    "        \n",
    "        # Set 2\n",
    "        out = F.elu(self.cnn2(out), inplace=True) \n",
    "        \n",
    "        # Set 3\n",
    "        out = F.elu(self.cnn3(out), inplace=True)  \n",
    "        \n",
    "        # Set 4\n",
    "        out = F.elu(self.cnn4(out), inplace=True) \n",
    "        \n",
    "        # Set 5\n",
    "        out = F.elu(self.cnn5(out), inplace=True)\n",
    "        \n",
    "        # Set 6\n",
    "        out = F.elu(self.cnn6(out), inplace=True)\n",
    "        \n",
    "        # Set 7\n",
    "        out = F.elu(self.cnn7(out), inplace=True)\n",
    "\n",
    "        # Set 8\n",
    "        out = self.cnn8(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90f22ae-c841-474a-aa35-416223b4dee8",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101555a9-0408-469d-b844-f9f8ce5499fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = DnCNN_noise()\n",
    "model1.load_state_dict(torch.load('noisemodelv2.2.1_450epochs'))\n",
    "model1.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0950116-6698-4fe8-b5c4-b29b84f2d2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = DnCNN_noise_era5()\n",
    "model2.load_state_dict(torch.load('noisemodelv2.2.1_450epochs'))\n",
    "model2.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2516730b-d1a2-4097-81c6-3128d99c5bea",
   "metadata": {},
   "source": [
    "## Generate SSIM dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aa5e72-1297-4552-ac03-8926eccb792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssim_lists(model, data_loader):\n",
    "    # Calculate val SSIM \n",
    "    ssim_list_uncorrected = []\n",
    "    ssim_list_model_corrected = []\n",
    "    ssim_list_era5_corrected = []\n",
    "    ssim_list_hp_corrected = []\n",
    "    \n",
    "    for i, (sample, signal_target, noise_target, era5_noise, dem, era5_corr, hp_corr) in enumerate(data_loader):\n",
    "        # uncorrected SSIM\n",
    "        ssim_value_uncorrected = ssim(sample.squeeze().detach().numpy(), signal_target.squeeze().detach().numpy(),\n",
    "                         gaussian_weights=True)\n",
    "        ssim_list_uncorrected.append(ssim_value_uncorrected)\n",
    "    \n",
    "        # model corrected SSIM\n",
    "        noise = model(sample.to('cuda'), dem.to('cuda')) #Generate predictions using the model\n",
    "        signal = torch.clamp(sample.to('cpu') - noise.to('cpu'), -1, 1)\n",
    "        ssim_value_model_corrected = ssim(signal.squeeze().detach().numpy(), signal_target.squeeze().detach().numpy(),\n",
    "                         gaussian_weights=True)\n",
    "        ssim_list_model_corrected.append(ssim_value_model_corrected)\n",
    "    \n",
    "        # era5 corrected SSIM\n",
    "        ssim_value_era5_corrected = ssim(era5_corr.squeeze().numpy(), signal_target.squeeze().numpy(),\n",
    "                         gaussian_weights=True)\n",
    "        ssim_list_era5_corrected.append(val_ssim_value_era5_corrected)\n",
    "    \n",
    "        # hp filter corrected SSIM\n",
    "        ssim_value_hp_corrected = ssim(hp_corr.squeeze().numpy(), signal_target.squeeze().numpy(),\n",
    "                         gaussian_weights=True)\n",
    "        ssim_list_hp_corrected.append(ssim_value_hp_corrected)\n",
    "    \n",
    "    \n",
    "    print('mean ssim before correction:', np.mean(ssim_list_uncorrected),\n",
    "          '\\nmean ssim model correction:', np.mean(ssim_list_model_corrected), \n",
    "          '\\nmean ssim era5 correction:', np.mean(ssim_list_era5_corrected),\n",
    "          '\\nmean ssim high pass filter correction:', np.mean(ssim_list_hp_corrected))\n",
    "    \n",
    "    return ssim_list_uncorrected, ssim_list_model_corrected, ssim_list_era5_corrected, ssim_list_hp_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1509a4ba-6d79-46ea-a17b-fe0d562d74c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1val_ssim_list_uncorrected, m1val_ssim_list_model, m1val_ssim_list_era5, m1val_ssim_list_hp = ssim_lists(model1, val_loader)\n",
    "m1train_ssim_list_uncorrected, m1train_ssim_list_model, m1train_ssim_list_era5, m1train_ssim_list_hp = ssim_lists(model1, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e66624-45de-4e49-9f5f-4e34e2283cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2val_ssim_list_uncorrected, m2val_ssim_list_model, m2val_ssim_list_era5, m2val_ssim_list_hp = ssim_lists(model2, val_loader)\n",
    "m2train_ssim_list_uncorrected, m2train_ssim_list_model, m2train_ssim_list_era5, m2train_ssim_list_hp = ssim_lists(model2, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb21d3f-62d2-4070-b455-736c4eff2673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SNR\n",
    "def rms(tensor):\n",
    "    rms = np.sqrt(np.mean(tensor.squeeze().numpy()**2))\n",
    "    return rms\n",
    "\n",
    "def snr(model, data_loader):\n",
    "    snr_list = []\n",
    "\n",
    "    for i, (sample, signal_target, noise_target, era5_noise, dem, era5_corr, hp_corr) in enumerate(data_loader):\n",
    "        snr_list.append(rms(signal_target)/rms(sample-signal_target))\n",
    "\n",
    "    print('mean snr of images:', np.mean(snr_list))\n",
    "    \n",
    "    return snr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeec65a-b4ec-4f0d-a6f8-d0599c6e5d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1val_snr_list = snr(model1, val_loader)\n",
    "m1train_snr_list = snr(model1, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a667173-b151-4637-83aa-89f443794172",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2val_snr_list = snr(model2, val_loader)\n",
    "m2train_snr_list = snr(model2, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364e174c-e6ec-4e11-b8db-4ff5a8cd0b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_for_plotting(snr_list, ssim_list_uncorrected, ssim_list_model, ssim_list_era5, ssim_list_hp):\n",
    "\n",
    "    roll_count = 200\n",
    "    q_low = 25\n",
    "    q_high = 75\n",
    "\n",
    "    ssim_dict = {'snr': snr_list,\n",
    "                     'ssim_uncorrected':ssim_list_uncorrected,\n",
    "                     'ssim_model':ssim_list_model,\n",
    "                     'ssim_era5':ssim_list_era5, \n",
    "                     'ssim_hp':ssim_list_hp}\n",
    "    ssim_df = pd.DataFrame(ssim_dict)\n",
    "\n",
    "    # uncorrected ssim\n",
    "    ssim_df['ssim_uncorrected_median'] = ssim_df.sort_values(by=['snr']).ssim_uncorrected.rolling(roll_count, center=True).median()\n",
    "    ssim_df[f'ssim_uncorrected_q{q_low}'] = ssim_df.sort_values(by=['snr']).ssim_uncorrected.rolling(roll_count, center=True).quantile(quantile=q_low/100)\n",
    "    ssim_df[f'ssim_uncorrected_q{q_high}'] = ssim_df.sort_values(by=['snr']).ssim_uncorrected.rolling(roll_count, center=True).quantile(quantile=q_high/100)\n",
    "\n",
    "    # model corrected ssim\n",
    "    ssim_df['ssim_model_median'] = ssim_df.sort_values(by=['snr']).ssim_model.rolling(roll_count, center=True).median()\n",
    "    ssim_df[f'ssim_model_q{q_low}'] = ssim_df.sort_values(by=['snr']).ssim_model.rolling(roll_count, center=True).quantile(quantile=q_low/100)\n",
    "    ssim_df[f'ssim_model_q{q_high}'] = ssim_df.sort_values(by=['snr']).ssim_model.rolling(roll_count, center=True).quantile(quantile=q_high/100)\n",
    "\n",
    "    # era5 corrected ssim\n",
    "    ssim_df['ssim_era5_median'] = ssim_df.sort_values(by=['snr']).ssim_era5.rolling(roll_count, center=True).median()\n",
    "    ssim_df[f'ssim_era5_q{q_low}'] = ssim_df.sort_values(by=['snr']).ssim_era5.rolling(roll_count, center=True).quantile(quantile=q_low/100)\n",
    "    ssim_df[f'ssim_era5_q{q_high}'] = ssim_df.sort_values(by=['snr']).ssim_era5.rolling(roll_count, center=True).quantile(quantile=q_high/100)\n",
    "\n",
    "    # era5 corrected ssim\n",
    "    ssim_df['ssim_hp_median'] = ssim_df.sort_values(by=['snr']).ssim_hp.rolling(roll_count, center=True).median()\n",
    "    ssim_df[f'ssim_hp_q{q_low}'] = ssim_df.sort_values(by=['snr']).ssim_hp.rolling(roll_count, center=True).quantile(quantile=q_low/100)\n",
    "    ssim_df[f'ssim_hp_q{q_high}'] = ssim_df.sort_values(by=['snr']).ssim_hp.rolling(roll_count, center=True).quantile(quantile=q_high/100)\n",
    "    \n",
    "    return ssim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fce54eb-36df-4984-aa6c-b574a527b8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1val_ssim_df=df_for_plotting(m1val_snr_list, m1val_ssim_list_uncorrected, m1val_ssim_list_model, m1val_ssim_list_era5, m1val_ssim_list_hp)\n",
    "m1train_ssim_df=df_for_plotting(m1train_snr_list, m1train_ssim_list_uncorrected, m1train_ssim_list_model, m1train_ssim_list_era5, m1train_ssim_list_hp)\n",
    "m2val_ssim_df=df_for_plotting(m2val_snr_list, m2val_ssim_list_uncorrected, m2val_ssim_list_model, m2val_ssim_list_era5, m2val_ssim_list_hp)\n",
    "m2train_ssim_df=df_for_plotting(m2train_snr_list, m2train_ssim_list_uncorrected, m2train_ssim_list_model, m2train_ssim_list_era5, m2train_ssim_list_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad1e218-1bac-41ac-b8a0-bb61b1945ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
