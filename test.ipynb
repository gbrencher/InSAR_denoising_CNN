{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3303369c-b187-4576-9ff9-b04190e8de4e",
   "metadata": {},
   "source": [
    "# InSAR denoiser testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fd847d-4c5d-4be8-8935-a62b60208f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import math\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import rioxarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db817cf-f126-4a8c-b37e-7a91ea8ee132",
   "metadata": {},
   "source": [
    "## define network and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8f579f-131a-4143-9f22-998ba1a43465",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DnCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network model for InSAR denoising adapted from Rouet-Leduc et al., 2021\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        kernel_size=3\n",
    "        padding=1\n",
    "        features=64\n",
    "        channels=2\n",
    "        \n",
    "        # Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "        # Convolution 2\n",
    "        self.cnn2 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "        # Convolution 3\n",
    "        self.cnn3 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "        # Convolution 4\n",
    "        self.cnn4 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "        # Convolution 5\n",
    "        self.cnn5 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=5, dilation=5)\n",
    "        \n",
    "        # Convolution 6\n",
    "        self.cnn6 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=4, dilation=4)\n",
    "        \n",
    "        # Convolution 7\n",
    "        self.cnn7 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=2, dilation=2)\n",
    "        \n",
    "        # Convolution 8\n",
    "        self.cnn8 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "        # Convolution 9\n",
    "        self.cnn9 = nn.Conv2d(in_channels=features, out_channels=1, kernel_size=kernel_size, padding=padding)\n",
    "\n",
    "    def forward(self, x, dem):                \n",
    "        # Set 1\n",
    "        out = F.elu(self.cnn1(torch.cat((x, dem), dim=1)), inplace=True) \n",
    "        \n",
    "        # Set 2\n",
    "        out = F.elu(self.cnn2(out), inplace=True) \n",
    "        \n",
    "        # Set 3\n",
    "        out = F.elu(self.cnn3(out), inplace=True)  \n",
    "        \n",
    "        # Set 4\n",
    "        out = F.elu(self.cnn4(out), inplace=True) \n",
    "        \n",
    "        # Set 5\n",
    "        out = F.elu(self.cnn5(out), inplace=True) \n",
    "        \n",
    "        # Set 6\n",
    "        out = F.elu(self.cnn6(out), inplace=True)\n",
    "        \n",
    "        # Set 7\n",
    "        out = F.elu(self.cnn7(out), inplace=True) \n",
    "        \n",
    "        # Set 8\n",
    "        out = F.elu(self.cnn8(out), inplace=True)\n",
    "        \n",
    "        # Set 9\n",
    "        out = self.cnn9(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3830b5-f359-46ee-b520-9133ab0655ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "test_model = DnCNN()\n",
    "test_model.load_state_dict(torch.load('model_100_epochs'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11db6f4e-3918-48eb-9398-a59ee2ea7784",
   "metadata": {},
   "source": [
    "# Load tifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f04adc-ea77-4730-9a45-621fb1054c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tifs to xarray \n",
    "\n",
    "def ints_to_xarray(int_directory):\n",
    "    \n",
    "    dirs = os.listdir(hyp3_dir)\n",
    "    \n",
    "    int_datasets=[]\n",
    "    dem_datasets=[]\n",
    "    \n",
    "    for i, idir in enumerate(dirs):\n",
    "        cwd = f'{hyp3_dir}/{idir}'\n",
    "        os.chdir(cwd)\n",
    "\n",
    "        # select the los displacement and dem\n",
    "        allfiles = os.listdir(cwd)\n",
    "        for fn in allfiles:\n",
    "            if fn[-12:] == 'los_disp.tif':\n",
    "                int_tif = fn\n",
    "            elif fn[-7:] == 'dem.tif':\n",
    "                dem_tif = fn\n",
    "        int_fn = f'{hyp3_dir}/{idir}/{int_tif}'\n",
    "        dem_fn =  f'{hyp3_dir}/{idir}/{dem_tif}'\n",
    "        \n",
    "        da = rioxarray.open_rasterio(int_fn)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        if save_to_nc:\n",
    "            out_fn = str(pathlib.Path(file_name).with_suffix(\"\")) + \".nc\"\n",
    "            pathlib.Path(out_fn).unlink(missing_ok=True) #force delete file if exists\n",
    "            src.to_netcdf(out_fn)\n",
    "            out_dir = str(pathlib.Path(geotif_files_list[index]).parents[0])\n",
    "            nc_files.append(out_fn)\n",
    "            out_dirs.append(out_dir)\n",
    "\n",
    "        datasets.append(src)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
