{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3303369c-b187-4576-9ff9-b04190e8de4e",
   "metadata": {},
   "source": [
    "# InSAR denoiser testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fd847d-4c5d-4be8-8935-a62b60208f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import math\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import rioxarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db817cf-f126-4a8c-b37e-7a91ea8ee132",
   "metadata": {},
   "source": [
    "## define network and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8f579f-131a-4143-9f22-998ba1a43465",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DnCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network model for InSAR denoising adapted from Rouet-Leduc et al., 2021\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        kernel_size=3\n",
    "        padding=1\n",
    "        features=64\n",
    "        channels=2\n",
    "        \n",
    "        # Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "        # Convolution 2\n",
    "        self.cnn2 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "        # Convolution 3\n",
    "        self.cnn3 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "        # Convolution 4\n",
    "        self.cnn4 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "        # Convolution 5\n",
    "        self.cnn5 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=5, dilation=5)\n",
    "        \n",
    "        # Convolution 6\n",
    "        self.cnn6 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=4, dilation=4)\n",
    "        \n",
    "        # Convolution 7\n",
    "        self.cnn7 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=2, dilation=2)\n",
    "        \n",
    "        # Convolution 8\n",
    "        self.cnn8 = nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "        # Convolution 9\n",
    "        self.cnn9 = nn.Conv2d(in_channels=features, out_channels=1, kernel_size=kernel_size, padding=padding)\n",
    "\n",
    "    def forward(self, x, dem):                \n",
    "        # Set 1\n",
    "        out = F.elu(self.cnn1(torch.cat((x, dem), dim=1)), inplace=True) \n",
    "        \n",
    "        # Set 2\n",
    "        out = F.elu(self.cnn2(out), inplace=True) \n",
    "        \n",
    "        # Set 3\n",
    "        out = F.elu(self.cnn3(out), inplace=True)  \n",
    "        \n",
    "        # Set 4\n",
    "        out = F.elu(self.cnn4(out), inplace=True) \n",
    "        \n",
    "        # Set 5\n",
    "        out = F.elu(self.cnn5(out), inplace=True) \n",
    "        \n",
    "        # Set 6\n",
    "        out = F.elu(self.cnn6(out), inplace=True)\n",
    "        \n",
    "        # Set 7\n",
    "        out = F.elu(self.cnn7(out), inplace=True) \n",
    "        \n",
    "        # Set 8\n",
    "        out = F.elu(self.cnn8(out), inplace=True)\n",
    "        \n",
    "        # Set 9\n",
    "        out = self.cnn9(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3830b5-f359-46ee-b520-9133ab0655ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "test_model = DnCNN()\n",
    "test_model.load_state_dict(torch.load('model_100_epochs'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11db6f4e-3918-48eb-9398-a59ee2ea7784",
   "metadata": {},
   "source": [
    "# Load tifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61afdbd1-2e0c-4204-846f-93ae8054d5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to load interferogram tifs to xarray\n",
    "\n",
    "def xr_read_geotif(geotif_file_path, chunks='auto', masked=True):\n",
    "    \"\"\"\n",
    "    Reads in single or multi-band GeoTIFF as dask array.\n",
    "    Inputs\n",
    "    ----------\n",
    "    GeoTIFF_file_path : GeoTIFF file path\n",
    "    Returns\n",
    "    -------\n",
    "    ds : xarray.Dataset\n",
    "        Includes rioxarray extension to xarray.Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    da = rioxarray.open_rasterio(geotif_file_path, chunks=chunks, masked=True)\n",
    "\n",
    "    # Extract bands and assign as variables in xr.Dataset()\n",
    "    ds = xr.Dataset()\n",
    "    for i, v in enumerate(da.band):\n",
    "        da_tmp = da.sel(band=v)\n",
    "        da_tmp.name = \"band\" + str(i + 1)\n",
    "\n",
    "        ds[da_tmp.name] = da_tmp\n",
    "\n",
    "    # Delete empty band coordinates.\n",
    "    # Need to preserve spatial_ref coordinate, even though it appears empty.\n",
    "    # See spatial_ref attributes under ds.coords.variables used by rioxarray extension.\n",
    "    del ds.coords[\"band\"]\n",
    "\n",
    "    # Preserve top-level attributes and extract single value from value iterables e.g. (1,) --> 1\n",
    "    ds.attrs = da.attrs\n",
    "    for key, value in ds.attrs.items():\n",
    "        try:\n",
    "            if len(value) == 1:\n",
    "                ds.attrs[key] = value[0]\n",
    "        except TypeError:\n",
    "            pass\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def hyp3_to_xarray(hyp3_dir, file_type='unw_phase'):\n",
    "    \n",
    "    dirs = os.listdir(hyp3_dir) #list generated interferograms\n",
    "    datasets = []\n",
    "    \n",
    "    for idir in dirs:\n",
    "        cwd = f'{hyp3_dir}/{idir}'\n",
    "        os.chdir(cwd) #change to interferogram dir\n",
    "\n",
    "        ext = f'{file_type}.tif' #end of filename for desired hyp3 product\n",
    "        \n",
    "        for fn in os.listdir(cwd): #select appropriate hyp3 product\n",
    "            if fn[-len(ext):] == ext: \n",
    "                tif_fn = fn\n",
    "        tif_path = f'{hyp3_dir}/{idir}/{tif_fn}'\n",
    "        dates = f'{tif_fn[5:13]}_{tif_fn[21:29]}' #parse filename for interferogram dates\n",
    "        \n",
    "        src = xr_read_geotif(tif_path, masked=False) #read product to xarray ds \n",
    "        src = src.assign_coords({\"dates\": dates})\n",
    "        src = src.expand_dims(\"dates\")\n",
    "        \n",
    "        datasets.append(src)\n",
    "       \n",
    "    ds = xr.concat(datasets, dim=\"dates\", combine_attrs=\"no_conflicts\") #create dataset\n",
    "    return ds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18733dc-3bc4-410e-8d47-bde49e22f9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open ints and dems\n",
    "hyp3_dir = '/Users/qbren/Desktop/taco/projects/atmospheric_correction/data_processing/test_data/asc_crop'\n",
    "\n",
    "int_xarray = hyp3_to_xarray(hyp3_dir)\n",
    "\n",
    "dem_fn = ''\n",
    "dem_src = rio.open(f'{hyp3_dir}/{dem_fn}')\n",
    "dem_np = dem_src.read(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f04adc-ea77-4730-9a45-621fb1054c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to prepare arrays for model run\n",
    "def arrays_to_tensor(int_array, dem_array, norm=True):\n",
    "    test_tensor = torch.Tensor(array.to_numpy())\n",
    "    dem_tensor = torch.Tensor(dem_array)\n",
    "    \n",
    "    if norm=True:\n",
    "        test_tensor = 2*(((test_tensor-(test_tensor.min()))/(test_tensor.max()-(test_tensor.min()))))-1\n",
    "        dem_tensor = 2*(((dem_tensor-(dem_tensor.min()))/(dem_tensor.max()-(dem_tensor.min()))))-1\n",
    "    \n",
    "    return test_tensor, dem_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97011494-7334-423c-b910-0e870d3108e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run test interferograms through model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
